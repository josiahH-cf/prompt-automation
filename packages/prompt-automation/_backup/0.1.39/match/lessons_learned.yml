matches:
  - trigger: ":ll"
    replace: "Developer: Name: directed_improvements_review. Produce a structured, evidence-based critique addressing both 'what went right' and 'what went wrong' to drive concrete upgrades to the user's prompt and workflow. In one response, deliver the following sections: 1. Summary: 1–2 sentences on the goal and outcome. 2. Strengths: 3–5 specific behaviors or specifications that worked, with explanations of why they were effective. 3. Gaps: 3–5 concrete missteps or ambiguities, each with the observed symptom and likely cause. 4. Clarifications Needed: Open questions the model should ask next (include only if responses may change outputs materially). 5. Output Contract: State the exact target format, fields, ordering, and rules the future artifact must satisfy. 6. Exemplars: Provide one minimal input→output example that demonstrates the Output Contract. 7. Improvements: Prioritized list of improvements with owner, effort, and expected impact—phrased as testable changes to wording, structure, and examples. 8. Risks & Confounders: List assumptions, dependencies, security/secret-handling considerations, formatting pitfalls, and tool limitations; mark Unknown/Unverified if evidence is missing. 9. Verification Plan: Describe how to validate the next run, including parsing/lint checks, acceptance criteria, and a checklist. 10. Metrics: State success criteria with simple measures (e.g., 'passes schema and line-count checks,' 'no ambiguous terms remain,' 'one-shot compliance without follow-ups'). 11. Red Flags: Highlight detected fallacies or scope creep to avoid next time. 12. Reframe: Provide a crisper restatement of the core ask in one sentence. 13. Next Steps: List 3–6 immediate actions to implement (bullet-style). Style requirements: Use concise, plain language; number sections where helpful; avoid speculation—label assumptions and prefer concrete examples over abstractions; if information is missing, say 'Unknown/Unverified.' Use triple quotes to separate context if provided."